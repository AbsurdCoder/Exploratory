{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Vector\n",
    "size of feature vector should be  equal to number of unique vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer() #removing s and eds eg: dog and dogs will be the same.\n",
    "\n",
    "stopwords = set(w.rstrip() for w in open('stopwords.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = BeautifulSoup(open('electronics/positive.review')) # It's getting HTML page with tags\n",
    "negative_reviews = BeautifulSoup(open('electronics/negative.review')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = positive_reviews.findAll('review_text') # Getting the information from <review_text> tag only\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_reviews), len(negative_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(positive_reviews) # Run the code with and without shuffle\n",
    "positive_reviews = positive_reviews[:len(negative_reviews)] # This is generally done assuming we have more positive reveiws than negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/vdna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is my vocab\n",
    "\n",
    "def my_tokenizer(s):\n",
    "    s = s.lower()\n",
    "    tokens = nltk.tokenize.word_tokenize(s)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # will remove all the words that has 2 or 1 character\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # Remove the extra characters in the word that has same meaning eg.. dog doggo dogs\n",
    "    tokens = [t for t in tokens if t not in stopwords] # remove stop words\n",
    "    return tokens\n",
    "\n",
    "word_index_map = {}\n",
    "current_index = 0\n",
    "\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "\n",
    "\n",
    "# Create a dictionary with the information of the words as keys and the count as the value of the corresponding key.\n",
    "for review in positive_reviews:\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "            \n",
    "            \n",
    "for review in negative_reviews:\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1)\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] += 1\n",
    "    x = x / x.sum()\n",
    "    x[-1] = label\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = len(positive_tokenized) + len(negative_tokenized)\n",
    "data = np.zeros((N, len(word_index_map) + 1))\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "    \n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :-1]\n",
    "Y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = X[:-100,]\n",
    "YTrain = Y[:-100,]\n",
    "XTest = X[-100:,]\n",
    "YTest = Y[-100:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vdna/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification rate: 0.76\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(XTrain, YTrain)\n",
    "print(\"Classification rate:\", model.score(XTest, YTest))\n",
    "\n",
    "y_pred = model.predict(XTest)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(YTest, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 13],\n",
       "       [11, 38]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month -0.6940848225936085\n",
      "wa -1.6350301090818566\n",
      "returned -0.7186174922897566\n",
      "home 0.5638609688102857\n",
      "sound 1.0557049809184174\n",
      "quality 1.3957617498715775\n",
      "pretty 0.7581300719915276\n",
      "memory 0.9365689963631046\n",
      "using 0.6661514056964634\n",
      "time -0.6317244335435982\n",
      "you 0.8974237685222535\n",
      "then -1.042589355907795\n",
      "perfect 0.8865304805888062\n",
      "try -0.6799769771285681\n",
      "customer -0.6647329173795671\n",
      "bit 0.6394525286211961\n",
      "price 2.661032634881903\n",
      "love 1.13110204082786\n",
      "'ve 0.708655331743074\n",
      "n't -2.040592582424689\n",
      "ha 0.6059217953423799\n",
      "little 0.9223445509555118\n",
      "buy -0.8403640965557254\n",
      "bad -0.7224359213656332\n",
      "tried -0.7876087853912271\n",
      "static -0.501321119501028\n",
      "poor -0.7921364634737701\n",
      "doe -1.2821508041761982\n",
      "lot 0.7391783625489634\n",
      "money -1.1117215508998581\n",
      "cable 0.6194154028623847\n",
      "video 0.5236089100682628\n",
      "look 0.5637730253173404\n",
      "week -0.6927445068432616\n",
      "fast 0.8694183823387399\n",
      "happy 0.6592196787892529\n",
      "support -0.9097749861376206\n",
      "company -0.5501920884844786\n",
      "recommend 0.5907278840377777\n",
      "highly 0.9508616293039409\n",
      "speaker 0.879752165056543\n",
      "unit -0.7531533041569368\n",
      "paper 0.6459640293670703\n",
      "excellent 1.3649358512155396\n",
      "warranty -0.6263381964293175\n",
      "expected 0.6076579680429576\n",
      "easy 1.8686820539172522\n",
      "space 0.5356999023829915\n",
      "comfortable 0.620333634787183\n",
      "value 0.5324618006501274\n",
      "junk -0.544776137651547\n",
      "returning -0.5071374729151008\n",
      "item -0.958168111824317\n",
      "waste -0.9919933077345794\n",
      "refund -0.5806195024667015\n",
      "return -1.1236954079654058\n"
     ]
    }
   ],
   "source": [
    "for word, index in word_index_map.items():\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different Classifiers\n",
    "# Try different Features - we uses normallize vector\n",
    "# Try Regressoin\n",
    "# Try 5 categories instead of 2\n",
    "# Different catories of data     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
